{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.9428\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8674\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8055\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7543\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7115\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6754\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6446\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6181\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5950\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5745\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5562\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5397\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5246\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5107\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4977\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4856\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4740\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4631\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4526\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4426\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4329\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4236\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4145\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4057\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3971\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3888\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3807\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3727\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3650\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3574\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3500\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3428\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3357\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3288\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3220\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3154\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3089\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3026\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2963\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2902\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2843\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2784\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2727\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2671\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2616\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2562\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2510\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2458\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2408\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2358\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2310\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2262\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2216\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2170\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2126\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2082\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2039\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1998\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1956\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1916\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1877\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1838\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1801\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1764\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1727\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1692\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1657\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1623\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1590\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1557\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1525\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1494\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1463\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1433\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1404\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1375\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1347\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1319\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1292\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1265\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1239\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1214\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1189\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1164\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1141\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1117\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1094\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1072\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1050\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1028\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1007\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0986\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0966\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0946\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0927\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0908\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0889\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0871\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0853\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0835\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0818\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0801\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0785\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0769\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0753\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0738\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0722\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0708\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0693\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0679\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0665\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0651\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0638\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0625\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0612\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0599\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0587\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0575\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0563\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0552\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0540\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0529\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0518\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0508\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0497\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0487\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0477\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0467\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0458\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0448\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0439\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0430\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0421\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0413\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0404\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0396\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0388\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0380\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0372\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0364\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0357\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0349\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0342\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0335\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0328\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0322\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0315\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0309\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0302\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0296\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0290\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0284\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0278\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0272\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0267\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0261\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0256\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0251\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0246\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0240\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0236\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0231\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0226\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0221\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0217\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0212\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0208\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0204\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0200\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0195\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0191\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0187\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0184\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0180\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0176\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0173\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0169\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0166\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0162\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0159\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0156\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0152\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0149\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0146\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0143\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0140\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0137\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0135\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0132\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0129\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0126\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0124\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0121\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0119\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0116\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0114\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0112\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0109\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0107\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0105\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0103\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0101\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0099\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0096\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0095\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0093\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0091\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0089\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0087\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0085\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0083\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0082\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0080\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0078\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0077\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0075\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0074\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0072\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0071\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0069\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0068\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0066\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0065\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0064\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0062\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0061\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0060\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0059\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0057\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0056\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0055\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0054\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0053\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0052\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0051\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0050\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0049\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0048\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0047\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0046\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0045\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0044\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0043\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0042\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0041\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0040\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0040\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0039\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0038\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0037\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0036\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0036\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0035\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0034\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0033\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0032\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0031\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0031\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0030\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0029\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0028\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0028\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0027\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0027\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0026\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0025\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0025\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0024\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0024\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0023\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0023\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0022\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0021\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0021\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0020\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0020\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0019\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0019\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0018\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0018\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0017\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0017\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0017\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0016\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0016\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0016\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0015\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0015\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0014\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0014\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0013\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0013\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0013\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0012\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0012\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0012\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0011\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0011\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0011\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0010\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0010\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0010\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 9.8405e-04\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.6384e-04\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.4404e-04\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.2465e-04\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 9.0565e-04\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.8705e-04\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.6883e-04\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 8.5098e-04\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.3350e-04\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.1638e-04\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.9962e-04\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.8319e-04\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.6710e-04\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.5134e-04\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.3591e-04\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.2080e-04\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.0599e-04\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.9149e-04\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.7728e-04\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.6337e-04\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.4975e-04\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.3640e-04\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.2333e-04\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.1052e-04\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9799e-04\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.8570e-04\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7367e-04\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.6189e-04\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.5035e-04\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.3905e-04\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.2797e-04\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.1713e-04\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.0651e-04\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.9610e-04\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.8591e-04\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7593e-04\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.6616e-04\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.5658e-04\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.4720e-04\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.3801e-04\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.2902e-04\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.2021e-04\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.1158e-04\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.0312e-04\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9484e-04\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.8673e-04\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.7879e-04\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7101e-04\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.6339e-04\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5592e-04\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.4861e-04\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4145e-04\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.3443e-04\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.2756e-04\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.2084e-04\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.1424e-04\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0779e-04\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.0147e-04\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.9528e-04\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.8921e-04\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.8327e-04\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.7745e-04\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.7175e-04\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.6617e-04\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6070e-04\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.5535e-04\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.5010e-04\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.4497e-04\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3994e-04\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3501e-04\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3018e-04\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2545e-04\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2082e-04\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1628e-04\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.1184e-04\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.0749e-04\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0323e-04\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9906e-04\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9496e-04\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9096e-04\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.8704e-04\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8319e-04\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7943e-04\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7575e-04\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7214e-04\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6860e-04\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6514e-04\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.6175e-04\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.5842e-04\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5517e-04\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5198e-04\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4886e-04\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4580e-04\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4281e-04\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3988e-04\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3700e-04\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3419e-04\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3143e-04\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.2873e-04\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2609e-04\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2350e-04\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2096e-04\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1848e-04\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1604e-04\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1366e-04\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1133e-04\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0904e-04\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0680e-04\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0460e-04\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0246e-04\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0035e-04\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.8291e-05\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 9.6271e-05\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 9.4293e-05\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.2357e-05\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 9.0459e-05\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.8602e-05\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8.6782e-05\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8.4999e-05\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.3253e-05\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.1544e-05\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.9869e-05\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.8229e-05\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6622e-05\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5048e-05\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.3506e-05\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.1997e-05\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.0518e-05\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.9069e-05\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.7650e-05\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.6261e-05\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.4899e-05\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.3566e-05\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.2262e-05\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.0983e-05\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.9729e-05\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.8503e-05\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.7301e-05\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.6125e-05\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4972e-05\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.3842e-05\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.2736e-05\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.1654e-05\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.0592e-05\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.9553e-05\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.8535e-05\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.7538e-05\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.6562e-05\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 4.5606e-05\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4670e-05\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3753e-05\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.2853e-05\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1972e-05\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1111e-05\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0266e-05\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.9439e-05\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.8630e-05\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.7835e-05\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3.7058e-05\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.6298e-05\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.5552e-05\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.4821e-05\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.4107e-05\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.3406e-05\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.2719e-05\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.2047e-05\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.1389e-05\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.0744e-05\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.0114e-05\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.9495e-05\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.8890e-05\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.8296e-05\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7714e-05\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7146e-05\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.6588e-05\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.6041e-05\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.5507e-05\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.4983e-05\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4469e-05\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3966e-05\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.3474e-05\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2992e-05\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2520e-05\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2058e-05\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1604e-05\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.1161e-05\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0726e-05\n",
      "1/1 [==============================] - 0s 453ms/step\n",
      "[[18.986717]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-1, 0, 1, 2, 3, 4], dtype=float)\n",
    "y = np.array([-3, -1, 1, 3, 5, 7], dtype=float)\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "# sgd = stochastic gradient descent\n",
    "model.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")\n",
    "model.fit(x, y, epochs=500)  # epochs = number of iterations\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that house pricing is as easy as:\n",
    "\n",
    "A house has a base cost of 50k, and every additional bedroom adds a cost of 50k. This will make a 1 bedroom house cost 100k, a 2 bedroom house cost 150k etc.\n",
    "\n",
    "How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 58238.0352\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 27088.6719\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12670.8311\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5996.8501\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2906.9675\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1475.9181\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 812.6358\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 504.7043\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 361.2481\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 293.9222\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 261.8383\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 246.0725\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 237.8655\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 233.1641\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 230.0914\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 227.7792\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 225.8253\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 224.0439\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 222.3486\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 220.6993\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 219.0781\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 217.4757\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 215.8884\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 214.3140\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 212.7522\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 211.2019\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 209.6630\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 208.1355\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 206.6191\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 205.1136\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 203.6193\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 202.1357\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 200.6631\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 199.2010\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 197.7498\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 196.3091\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 194.8790\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 193.4592\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 192.0495\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 190.6504\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 189.2615\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 187.8826\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 186.5139\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 185.1550\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 183.8060\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 182.4668\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 181.1374\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 179.8177\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 178.5077\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 177.2071\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 175.9161\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 174.6345\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 173.3622\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 172.0992\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 170.8453\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 169.6005\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 168.3651\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 167.1383\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 165.9205\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 164.7118\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 163.5117\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 162.3205\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 161.1379\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 159.9640\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 158.7986\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 157.6415\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 156.4931\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 155.3529\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 154.2211\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 153.0975\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 151.9822\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 150.8748\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 149.7757\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 148.6845\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 147.6012\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 146.5258\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 145.4583\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 144.3987\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 143.3465\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 142.3022\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 141.2654\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 140.2363\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 139.2145\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 138.2003\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 137.1933\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 136.1939\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 135.2016\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 134.2167\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 133.2388\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 132.2681\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 131.3044\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 130.3478\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 129.3981\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 128.4553\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 127.5196\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 126.5903\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 125.6682\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 124.7526\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 123.8437\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 122.9413\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 122.0457\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 121.1566\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 120.2739\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 119.3976\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 118.5278\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 117.6643\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 116.8070\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 115.9560\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 115.1112\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 114.2724\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 113.4400\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 112.6135\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 111.7930\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 110.9784\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 110.1699\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 109.3674\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 108.5706\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 107.7796\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 106.9943\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 106.2147\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 105.4410\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 104.6728\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 103.9101\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 103.1531\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 102.4016\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 101.6555\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 100.9149\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 100.1796\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 99.4498\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 98.7252\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 98.0060\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 97.2920\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 96.5832\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 95.8796\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 95.1810\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 94.4874\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 93.7991\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 93.1157\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 92.4373\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 91.7639\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 91.0953\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 90.4316\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 89.7728\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 89.1187\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 88.4694\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 87.8249\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 87.1851\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 86.5498\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 85.9194\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 85.2933\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 84.6719\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 84.0551\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 83.4427\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 82.8347\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 82.2312\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 81.6321\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 81.0374\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 80.4469\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 79.8609\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 79.2791\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 78.7014\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 78.1280\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 77.5589\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 76.9938\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 76.4329\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 75.8759\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 75.3232\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 74.7745\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 74.2297\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 73.6889\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 73.1520\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 72.6191\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 72.0900\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 71.5647\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 71.0434\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 70.5257\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 70.0120\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 69.5019\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 68.9955\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 68.4929\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 67.9939\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 67.4985\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 67.0067\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 66.5185\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 66.0339\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 65.5529\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 65.0752\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 64.6011\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 64.1305\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 63.6632\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 63.1994\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 62.7389\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 62.2819\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 61.8281\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 61.3777\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 60.9305\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 60.4866\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 60.0460\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 59.6085\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 59.1743\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 58.7431\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 58.3152\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 57.8903\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 57.4685\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 57.0498\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 56.6342\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 56.2215\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 55.8119\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 55.4053\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 55.0016\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 54.6010\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 54.2031\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 53.8082\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 53.4162\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 53.0271\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 52.6407\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 52.2572\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 51.8765\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 51.4985\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 51.1234\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 50.7509\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 50.3811\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 50.0141\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 49.6497\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 49.2880\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 48.9289\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 48.5724\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 48.2185\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 47.8673\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 47.5185\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 47.1724\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 46.8287\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 46.4874\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 46.1487\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 45.8126\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 45.4788\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 45.1475\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 44.8185\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 44.4920\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 44.1679\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 43.8461\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 43.5267\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 43.2095\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 42.8948\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 42.5822\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 42.2719\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 41.9640\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 41.6583\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 41.3548\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 41.0534\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 40.7544\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 40.4575\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 40.1627\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 39.8701\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 39.5796\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 39.2912\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 39.0050\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 38.7209\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 38.4387\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 38.1587\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 37.8807\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 37.6047\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 37.3307\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 37.0587\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 36.7887\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 36.5207\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 36.2546\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 35.9905\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.7283\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 35.4680\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 35.2096\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 34.9531\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 34.6984\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 34.4456\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 34.1946\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 33.9455\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 33.6982\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 33.4527\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 33.2090\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 32.9670\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 32.7268\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 32.4884\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 32.2517\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 32.0167\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 31.7835\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 31.5519\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 31.3220\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 31.0938\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 30.8673\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 30.6424\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 30.4192\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 30.1975\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 29.9775\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 29.7591\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 29.5423\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 29.3271\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 29.1134\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 28.9013\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 28.6908\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 28.4817\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 28.2743\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 28.0682\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 27.8638\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 27.6608\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 27.4592\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 27.2592\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 27.0606\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 26.8634\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 26.6676\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 26.4734\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.2806\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 26.0891\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 25.8990\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 25.7103\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 25.5230\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 25.3370\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 25.1525\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 24.9692\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 24.7873\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 24.6067\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24.4274\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 24.2494\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 24.0727\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 23.8974\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 23.7233\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 23.5504\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 23.3789\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 23.2085\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 23.0395\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.8716\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 22.7050\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 22.5396\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22.3753\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 22.2123\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 22.0505\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 21.8899\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 21.7303\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 21.5721\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 21.4149\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 21.2589\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 21.1040\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 20.9503\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 20.7976\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 20.6461\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 20.4957\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 20.3463\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 20.1981\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 20.0510\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19.9049\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.7599\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.6159\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 19.4730\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 19.3311\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.1902\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.0505\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18.9117\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.7739\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.6371\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.5014\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.3665\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.2328\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.0999\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 17.9680\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.8371\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.7072\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 17.5781\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.4501\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 17.3230\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.1968\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17.0714\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.9471\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.8236\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.7011\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.5794\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.4586\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.3387\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.2196\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.1015\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 15.9842\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 15.8677\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 15.7521\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 15.6373\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 15.5234\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 15.4103\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 15.2981\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 15.1866\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 15.0759\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.9661\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.8571\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 14.7488\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.6414\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.5347\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 14.4288\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 14.3237\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.2193\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 14.1158\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 14.0129\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 13.9108\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.8094\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 13.7088\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 13.6090\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.5098\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 13.4114\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.3137\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.2167\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.1204\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 13.0248\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.9299\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.8357\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.7422\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 12.6494\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.5572\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 12.4658\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.3749\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.2848\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 12.1952\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.1064\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 12.0182\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.9306\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 11.8438\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 11.7574\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 11.6718\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 11.5867\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11.5023\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.4185\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.3353\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11.2527\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11.1708\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.0894\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 11.0086\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 10.9284\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 10.8487\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.7697\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.6912\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.6134\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.5360\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.4593\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.3831\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.3074\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.2323\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.1578\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 10.0838\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.0103\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.9374\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.8650\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.7931\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.7218\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 9.6510\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.5806\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 9.5108\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.4415\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.3728\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.3044\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.2367\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.1694\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.1026\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0363\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.9704\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.9050\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.8402\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.7758\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.7118\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.6483\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.5854\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.5228\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.4607\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.3991\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3379\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.2771\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.2168\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1570\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.0975\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.0385\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9800\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.9218\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.8641\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.8068\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7499\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.6935\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.6374\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.5818\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.5266\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.4717\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4173\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.3632\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3096\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2563\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.2035\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1510\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.0989\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0472\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.9958\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9449\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8943\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.8441\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.7942\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.7447\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6956\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.6468\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.5983\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.5503\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5026\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.4552\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.4081\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.3615\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3151\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.2691\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.2234\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.1781\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.1331\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.0884\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0440\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.0000\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9563\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.9129\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.8698\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.8270\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.7846\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.7424\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.7006\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.6591\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6179\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5769\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5363\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4960\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.4559\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.4162\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3767\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3375\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.2986\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.2601\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.2217\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1837\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1459\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.1084\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.0712\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0342\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.9976\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.9612\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.9250\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.8892\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8535\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.8182\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.7831\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.7482\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.7136\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.6793\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.6452\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.6113\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.5778\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.5444\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5113\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.4784\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.4458\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4134\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.3813\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.3494\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.3177\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.2862\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.2550\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.2240\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1932\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.1626\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.1323\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.1022\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0723\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.0427\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.0132\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9840\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9549\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9261\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8975\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8691\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8409\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.8129\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7852\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7576\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7302\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7030\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6761\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.6493\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6227\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.5963\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.5701\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.5441\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5183\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4926\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4672\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.4419\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.4169\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.3919\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.3672\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3427\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.3183\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.2942\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.2702\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.2464\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.2227\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.1992\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.1759\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1528\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.1298\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.1070\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.0844\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.0619\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.0396\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.0174\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.9955\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9736\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.9520\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.9305\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.9091\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.8879\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.8669\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.8460\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.8253\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8047\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7842\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.7640\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.7438\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.7238\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7040\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6843\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.6647\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.6453\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6261\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6069\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5879\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5691\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5504\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5318\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5133\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.4950\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4768\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4588\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4409\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4231\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4054\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3879\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3705\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.3533\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3361\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3191\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3022\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2854\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2688\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2522\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2358\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2196\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2034\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1873\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.1714\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1556\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1399\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1243\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.1088\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.0934\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.0782\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.0630\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.0480\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.0331\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0183\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0036\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9890\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9745\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.9601\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.9458\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9316\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9176\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9036\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.8897\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8760\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.8623\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8487\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.8353\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.8219\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8086\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7954\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7824\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7694\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7565\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7437\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7310\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7184\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7058\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6934\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6811\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6688\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6567\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6446\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6326\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6207\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.6089\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5972\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5856\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5740\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5625\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5512\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5399\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5286\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5175\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5065\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4955\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4846\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4738\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4630\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4524\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4418\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4313\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4209\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4105\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4002\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3900\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3799\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3699\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3599\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3500\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3401\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3304\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3207\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3111\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3015\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2920\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2826\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2732\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2640\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2548\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2456\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2366\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2275\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2186\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2097\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2009\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1922\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1835\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1749\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1663\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1578\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1494\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1410\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1327\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1244\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1162\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1081\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1000\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0920\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0840\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0762\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0683\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0605\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0528\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0451\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0375\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0300\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0225\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0150\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0076\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0003\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9930\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9858\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9786\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9715\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9644\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9573\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9504\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9434\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9366\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9297\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9230\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9162\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9096\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9029\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8964\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8898\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8833\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8769\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8705\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8642\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8579\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8516\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8454\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8393\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8332\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8271\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8211\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8151\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8092\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8033\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7974\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7916\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7858\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7801\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7744\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7688\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7632\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7576\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7521\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7466\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7412\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7358\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.7304\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7251\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7198\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7146\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7094\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7042\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6991\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6940\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6889\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6839\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6789\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6740\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6691\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6642\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6593\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6545\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6498\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6450\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6403\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6357\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6310\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6264\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6219\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6174\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6129\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6084\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6040\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5996\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5952\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5908\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5865\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5823\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5780\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5738\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5696\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5655\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5614\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5573\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5532\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5492\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5452\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5412\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5373\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5334\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5295\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5256\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5218\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5180\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5142\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5105\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5067\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5031\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4994\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4957\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4921\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4886\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4850\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4815\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4779\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4745\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4710\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4676\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4642\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4608\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4574\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4541\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4508\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4475\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4443\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4410\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4378\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4346\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4314\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4283\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4252\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4221\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4190\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4160\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4129\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4099\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4069\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4040\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4010\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3981\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3952\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3923\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3895\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3866\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3838\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3810\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3782\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3755\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3728\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3700\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3673\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3647\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3620\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3594\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3568\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3542\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3516\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3490\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3465\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3439\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3414\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3389\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3365\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3340\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3316\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3292\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3268\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3244\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3220\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3197\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3174\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3151\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3128\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3105\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3082\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3060\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3037\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3015\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2993\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2971\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2950\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2928\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2907\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2886\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2865\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2844\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2823\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2803\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2782\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2762\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2742\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2722\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2702\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2682\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2663\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2643\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2624\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2605\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2586\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2567\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2549\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2530\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2512\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2493\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2475\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2457\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2439\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2421\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2404\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2386\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2369\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2352\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2334\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2317\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2301\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2284\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2267\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2251\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2234\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2218\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2202\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2186\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2170\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2154\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2138\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2123\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2107\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2092\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2077\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2062\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2047\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2032\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2017\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2002\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1988\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1973\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1959\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1944\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1930\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1916\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1902\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1888\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1875\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1861\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1847\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1834\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1821\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1807\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1794\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1781\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1768\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1755\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1742\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1730\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1717\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1705\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "[400.59552]\n"
     ]
    }
   ],
   "source": [
    "def house_model():\n",
    "    # START CODE HERE\n",
    "\n",
    "    # Define input and output tensors with the values for houses with 1 up to 6 bedrooms\n",
    "    # Hint: Remember to explictly set the dtype as float\n",
    "    xs = np.array([1, 2, 3, 4, 5, 6], dtype=float)\n",
    "    ys = 50 + 50 * xs\n",
    "\n",
    "    # Define your model (should be a model with 1 dense layer and 1 unit)\n",
    "    # Note: you can use `tf.keras` instead of `keras`\n",
    "    model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "\n",
    "    # Compile your model\n",
    "    # Set the optimizer to Stochastic Gradient Descent\n",
    "    # and use Mean Squared Error as the loss function\n",
    "    model.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")\n",
    "\n",
    "    # Train your model for 1000 epochs by feeding the i/o tensors\n",
    "    model.fit(xs, ys, epochs=1000)\n",
    "\n",
    "    # END CODE HERE\n",
    "    return model\n",
    "\n",
    "\n",
    "model = house_model()\n",
    "\n",
    "new_x = 7.0\n",
    "prediction = model.predict([new_x])[0]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion MNIST dataset\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Load the training and test split of the Fashion MNIST dataset\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the image\n",
    "index = 10\n",
    "\n",
    "plt.imshow(training_images[index])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28), 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images[index].shape, training_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values of the train and test images\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 10:48:09.752474: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 52s 25ms/step - loss: 0.4909 - accuracy: 0.8268\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.3692 - accuracy: 0.8666\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.3334 - accuracy: 0.8784\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3090 - accuracy: 0.8872\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2920 - accuracy: 0.8912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2c68279880>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the classification model\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 10ms/step - loss: 0.3687 - accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36871856451034546, 0.8666999936103821]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on unseen data\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(np.argmax(classifications[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "Helps determine the number of epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 7ms/step - loss: 0.4764 - accuracy: 0.8305\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.8686\n",
      "Loss is lower than 0.4 so cancelling training!\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3606 - accuracy: 0.8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d441af550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        '''\n",
    "        Halts the training when the loss falls below 0.4\n",
    "\n",
    "        Args:\n",
    "          epoch (integer) - index of epoch (required but unused in the function definition below)\n",
    "          logs (dict) - metric results from the training epoch\n",
    "        '''\n",
    "\n",
    "        # Check the loss\n",
    "        if (logs.get('loss') < 0.4):\n",
    "\n",
    "            # Stop if threshold is met\n",
    "            print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "# Instantiate class\n",
    "callbacks = myCallback()\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model with a callback\n",
    "model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 24s 12ms/step - loss: 0.4751 - accuracy: 0.8303\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.3579 - accuracy: 0.8683\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.3223 - accuracy: 0.8818\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.3000 - accuracy: 0.8878\n",
      "Epoch 5/10\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.2807 - accuracy: 0.8968\n",
      "Reached 99% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 23s 13ms/step - loss: 0.2809 - accuracy: 0.8967\n"
     ]
    }
   ],
   "source": [
    "# Remember to inherit from the correct class\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Define the correct function signature for on_epoch_end\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get(\"accuracy\") is not None and logs.get(\"accuracy\") > 0.89:\n",
    "            print(\"\\nReached 89% accuracy so cancelling training!\")\n",
    "\n",
    "            # Stop training once the above condition is met\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "def train_mnist(x_train, y_train):\n",
    "\n",
    "    # START CODE HERE\n",
    "\n",
    "    # Instantiate the callback class\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Fit the model for 10 epochs adding the callbacks\n",
    "    # and save the training history\n",
    "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
    "\n",
    "    # END CODE HERE\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "hist = train_mnist(training_images, training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "\n",
    "Extraction features in the image and applying pooling compresses the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               102528    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,386\n",
      "Trainable params: 113,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "MODEL TRAINING:\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.4643 - accuracy: 0.8328\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 48s 26ms/step - loss: 0.3186 - accuracy: 0.8830\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 48s 26ms/step - loss: 0.2721 - accuracy: 0.8992\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 48s 26ms/step - loss: 0.2436 - accuracy: 0.9086\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 48s 26ms/step - loss: 0.2182 - accuracy: 0.9186\n",
      "\n",
      "MODEL EVALUATION:\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2563 - accuracy: 0.9058\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "    # Add convolutions and max pooling\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Add the same layers as before\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Use same settings\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "print(f'\\nMODEL TRAINING:')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Evaluate on the test set\n",
    "print(f'\\nMODEL EVALUATION:')\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "f, axarr = plt.subplots(3, 4)\n",
    "\n",
    "FIRST_IMAGE = 0\n",
    "SECOND_IMAGE = 23\n",
    "THIRD_IMAGE = 28\n",
    "CONVOLUTION_NUMBER = 1\n",
    "\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(\n",
    "    inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "for x in range(0, 4):\n",
    "    f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[0, x].imshow(f1[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[0, x].grid(False)\n",
    "\n",
    "    f2 = activation_model.predict(\n",
    "        test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[1, x].imshow(f2[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[1, x].grid(False)\n",
    "\n",
    "    f3 = activation_model.predict(\n",
    "        test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[2, x].imshow(f3[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[2, x].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "\n",
    "# !wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n",
    "\n",
    "# !wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip\n",
    "# # Unzip the dataset\n",
    "# local_zip = \"./horse-or-human.zip\"\n",
    "# zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
    "# zip_ref.extractall(\"./horse-or-human\")\n",
    "# zip_ref.close()\n",
    "\n",
    "\n",
    "\n",
    "# # Unzip validation set\n",
    "# local_zip = \"./validation-horse-or-human.zip\"\n",
    "# zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
    "# zip_ref.extractall(\"./validation-horse-or-human\")\n",
    "\n",
    "# zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"./horse-or-human/\",  # This is the source directory for training images\n",
    "    target_size=(300, 300),  # All images will be resized to 300x300\n",
    "    batch_size=128,\n",
    "    # Since we use binary_crossentropy loss, we need binary labels\n",
    "    class_mode=\"binary\",\n",
    ")\n",
    "\n",
    "\n",
    "# Flow validation images in batches of 128 using validation_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    # This is the source directory for validation images\n",
    "    \"./validation-horse-or-human/\",\n",
    "    target_size=(300, 300),  # All images will be resized to 300x300\n",
    "    batch_size=32,\n",
    "    # Since you use binary_crossentropy loss, you need binary labels\n",
    "    class_mode=\"binary\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 21:18:00.134235: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-11 21:18:02.895935: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 727482368 exceeds 10% of free system memory.\n",
      "2024-03-11 21:18:08.505891: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 727482368 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 1:09 - loss: 0.6915 - accuracy: 0.5625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 21:18:10.081851: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 727482368 exceeds 10% of free system memory.\n",
      "2024-03-11 21:18:15.376176: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 727482368 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/8 [======>.......................] - ETA: 42s - loss: 1.1213 - accuracy: 0.5352 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 21:18:17.167965: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 727482368 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.8126 - accuracy: 0.5606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 21:18:51.401033: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 55s 6s/step - loss: 0.8126 - accuracy: 0.5606 - val_loss: 0.6819 - val_accuracy: 0.5000\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 53s 7s/step - loss: 0.6827 - accuracy: 0.5729 - val_loss: 0.6478 - val_accuracy: 0.6250\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 62s 8s/step - loss: 0.6819 - accuracy: 0.6129 - val_loss: 3.4250 - val_accuracy: 0.5000\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 59s 7s/step - loss: 0.8076 - accuracy: 0.7742 - val_loss: 0.5139 - val_accuracy: 0.7695\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 57s 7s/step - loss: 0.4586 - accuracy: 0.8154 - val_loss: 0.4957 - val_accuracy: 0.8359\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 60s 7s/step - loss: 0.4436 - accuracy: 0.8065 - val_loss: 1.6534 - val_accuracy: 0.7227\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 56s 7s/step - loss: 0.3969 - accuracy: 0.8486 - val_loss: 1.7748 - val_accuracy: 0.7461\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 51s 6s/step - loss: 0.4070 - accuracy: 0.8532 - val_loss: 0.7434 - val_accuracy: 0.7695\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 61s 8s/step - loss: 0.2116 - accuracy: 0.9232 - val_loss: 0.4760 - val_accuracy: 0.8984\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 60s 7s/step - loss: 0.2230 - accuracy: 0.9166 - val_loss: 1.3910 - val_accuracy: 0.8008\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 60s 7s/step - loss: 0.1556 - accuracy: 0.9444 - val_loss: 0.9619 - val_accuracy: 0.8594\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 55s 7s/step - loss: 0.1073 - accuracy: 0.9566 - val_loss: 0.6389 - val_accuracy: 0.9023\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 70s 9s/step - loss: 0.1638 - accuracy: 0.9377 - val_loss: 1.2768 - val_accuracy: 0.8320\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 60s 7s/step - loss: 0.2755 - accuracy: 0.9344 - val_loss: 0.8336 - val_accuracy: 0.7773\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 48s 6s/step - loss: 0.1042 - accuracy: 0.9633 - val_loss: 2.6367 - val_accuracy: 0.7773\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "        # This is the first convolution\n",
    "        tf.keras.layers.Conv2D(\n",
    "            16, (3, 3), activation=\"relu\", input_shape=(300, 300, 3)\n",
    "        ),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # The second convolution\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # The third convolution\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # The fourth convolution\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # The fifth convolution\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # Flatten the results to feed into a DNN\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # 512 neuron hidden layer\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=8,\n",
    "    epochs=15,\n",
    "    verbose=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss_acc(history):\n",
    "    \"\"\"Plots the training and validation loss and accuracy from a history object\"\"\"\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "    plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, \"bo\", label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, \"b\", label=\"Validation Loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 22:01:08.660855: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.8776 - accuracy: 0.4950"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 22:02:07.810029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 63s 7s/step - loss: 0.8776 - accuracy: 0.4950 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 64s 9s/step - loss: 0.6909 - accuracy: 0.5295 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 69s 8s/step - loss: 0.6893 - accuracy: 0.5146 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 57s 7s/step - loss: 0.6787 - accuracy: 0.6418 - val_loss: 0.6791 - val_accuracy: 0.5820\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 56s 7s/step - loss: 0.7454 - accuracy: 0.6263 - val_loss: 0.7388 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 57s 7s/step - loss: 0.6353 - accuracy: 0.6518 - val_loss: 0.8243 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 55s 8s/step - loss: 0.5614 - accuracy: 0.7108 - val_loss: 0.7898 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 56s 7s/step - loss: 0.5797 - accuracy: 0.6908 - val_loss: 0.8354 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 61s 7s/step - loss: 0.6206 - accuracy: 0.7139 - val_loss: 0.7715 - val_accuracy: 0.5273\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 57s 7s/step - loss: 0.6376 - accuracy: 0.7241 - val_loss: 0.8186 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 54s 8s/step - loss: 0.5522 - accuracy: 0.7341 - val_loss: 1.8208 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 56s 7s/step - loss: 0.5420 - accuracy: 0.7286 - val_loss: 0.6393 - val_accuracy: 0.5117\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 57s 7s/step - loss: 0.4961 - accuracy: 0.7753 - val_loss: 1.7393 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 56s 7s/step - loss: 0.4388 - accuracy: 0.7942 - val_loss: 1.6203 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 57s 7s/step - loss: 0.8568 - accuracy: 0.7375 - val_loss: 1.9346 - val_accuracy: 0.5000\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 54s 6s/step - loss: 0.4260 - accuracy: 0.7998 - val_loss: 2.7466 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 54s 8s/step - loss: 0.3886 - accuracy: 0.8343 - val_loss: 3.7259 - val_accuracy: 0.5000\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 56s 7s/step - loss: 0.4940 - accuracy: 0.7675 - val_loss: 1.9052 - val_accuracy: 0.5000\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 57s 7s/step - loss: 0.4547 - accuracy: 0.8042 - val_loss: 1.2375 - val_accuracy: 0.5000\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 56s 7s/step - loss: 0.3345 - accuracy: 0.8543 - val_loss: 0.4822 - val_accuracy: 0.6211\n"
     ]
    }
   ],
   "source": [
    "# Create new model\n",
    "model_for_aug = tf.keras.models.Sequential(\n",
    "    [\n",
    "        # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "        # This is the first convolution\n",
    "        tf.keras.layers.Conv2D(\n",
    "            16, (3, 3), activation=\"relu\", input_shape=(300, 300, 3)\n",
    "        ),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # The second convolution\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # The third convolution\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # The fourth convolution\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # The fifth convolution\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        # Flatten the results to feed into a DNN\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # 512 neuron hidden layer\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_for_aug.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "# This code has changed. Now instead of the ImageGenerator just rescaling\n",
    "# the image, we also rotate and do other operations\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './horse-or-human/',  # This is the source directory for training images\n",
    "    target_size=(300, 300),  # All images will be resized to 300x300\n",
    "    batch_size=128,\n",
    "    # Since we use binary_crossentropy loss, we need binary labels\n",
    "    class_mode='binary')\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    # This is the source directory for validation images\n",
    "    './validation-horse-or-human/',\n",
    "    target_size=(300, 300),  # All images will be resized to 300x300\n",
    "    batch_size=32,\n",
    "    # Since we use binary_crossentropy loss, we need binary labels\n",
    "    class_mode='binary')\n",
    "\n",
    "# Train the new model\n",
    "history_with_aug = model_for_aug.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=8,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_acc(history_with_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the training accuracy has gone down compared to the baseline. This is expected because (as a result of data augmentation) there are more variety in the images so the model will need more runs to learn from them. The good thing is the validation accuracy is no longer stalling and is more in line with the training results. This means that the model is now performing better on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = model.predict(images, batch_size=10)\n",
    "print(classes[0])\n",
    "\n",
    "if classes[0]>0.5:\n",
    "    print(fn + \" is a human\")\n",
    "else:\n",
    "    print(fn + \" is a horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "[0.50533926]\n",
      "horse5-060.png is a human\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "[0.39088556]\n",
      "horse1-510.png is a horse\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.45797282]\n",
      "horse6-198.png is a horse\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[0.48062184]\n",
      "horse5-259.png is a horse\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "[0.23324117]\n",
      "horse3-584.png is a horse\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[0.500299]\n",
      "horse4-389.png is a human\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "[0.45983103]\n",
      "horse1-122.png is a horse\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[0.4549614]\n",
      "horse4-000.png is a horse\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "[0.669657]\n",
      "horse2-136.png is a human\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[0.45571494]\n",
      "horse5-018.png is a horse\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[0.17287067]\n",
      "horse1-224.png is a horse\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[0.56940585]\n",
      "horse5-076.png is a human\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[0.4763758]\n",
      "horse4-345.png is a horse\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[0.5418748]\n",
      "horse2-383.png is a human\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.1509215]\n",
      "horse1-436.png is a horse\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.38542452]\n",
      "horse1-105.png is a horse\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.56456506]\n",
      "horse5-103.png is a human\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0.47699073]\n",
      "horse6-153.png is a horse\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.33158574]\n",
      "horse3-397.png is a horse\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[0.49173337]\n",
      "horse4-202.png is a horse\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[0.4219069]\n",
      "horse5-504.png is a horse\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.32593006]\n",
      "horse2-011.png is a horse\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "[0.5515876]\n",
      "horse5-065.png is a human\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[0.4697588]\n",
      "horse2-218.png is a horse\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[0.36825144]\n",
      "horse1-484.png is a horse\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[0.48332837]\n",
      "horse5-181.png is a horse\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[0.42402023]\n",
      "horse2-224.png is a horse\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.55871046]\n",
      "horse5-405.png is a human\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.5013416]\n",
      "horse3-011.png is a human\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.67187214]\n",
      "horse2-069.png is a human\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.51674277]\n",
      "horse6-544.png is a human\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.45224905]\n",
      "horse5-342.png is a horse\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.2862938]\n",
      "horse1-455.png is a horse\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.7373186]\n",
      "horse2-412.png is a human\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.4390781]\n",
      "horse5-303.png is a horse\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.42380014]\n",
      "horse5-235.png is a horse\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[0.77336967]\n",
      "horse2-596.png is a human\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[0.22733259]\n",
      "horse1-335.png is a horse\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[0.1344651]\n",
      "horse1-241.png is a horse\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[0.4520837]\n",
      "horse5-002.png is a horse\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.48067838]\n",
      "horse6-345.png is a horse\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[0.86448497]\n",
      "horse1-554.png is a human\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[0.7913772]\n",
      "horse3-498.png is a human\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.50330114]\n",
      "horse4-102.png is a human\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.516136]\n",
      "horse4-556.png is a human\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[0.47681785]\n",
      "horse4-439.png is a horse\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "[0.25475243]\n",
      "horse1-568.png is a horse\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[0.47119558]\n",
      "horse4-599.png is a horse\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.46058357]\n",
      "horse4-403.png is a horse\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[0.48556823]\n",
      "horse6-403.png is a horse\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[0.3335978]\n",
      "horse5-203.png is a horse\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.38527933]\n",
      "horse3-416.png is a horse\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.5140756]\n",
      "horse6-064.png is a human\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[0.4210923]\n",
      "horse5-458.png is a horse\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.4584385]\n",
      "horse3-440.png is a horse\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.5652466]\n",
      "horse4-043.png is a human\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.6458148]\n",
      "horse5-550.png is a human\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.45881355]\n",
      "horse4-014.png is a horse\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0.8149952]\n",
      "horse2-582.png is a human\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.77053326]\n",
      "horse3-484.png is a human\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0.3337355]\n",
      "horse3-198.png is a horse\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.5601337]\n",
      "horse4-501.png is a human\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.55573547]\n",
      "horse5-402.png is a human\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.80508053]\n",
      "horse5-032.png is a human\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.6096916]\n",
      "horse1-170.png is a human\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0.37346217]\n",
      "horse3-217.png is a horse\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[0.480661]\n",
      "horse4-541.png is a horse\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.69417006]\n",
      "horse5-164.png is a human\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0.5030252]\n",
      "horse4-159.png is a human\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.47539905]\n",
      "horse6-004.png is a horse\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.42098787]\n",
      "horse2-269.png is a horse\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.29910845]\n",
      "horse3-541.png is a horse\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[0.47335204]\n",
      "horse4-468.png is a horse\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[0.4598959]\n",
      "horse5-360.png is a horse\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[0.22580755]\n",
      "horse1-264.png is a horse\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.4061913]\n",
      "horse5-589.png is a horse\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.297312]\n",
      "horse1-539.png is a horse\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.5064984]\n",
      "horse2-040.png is a human\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.4671326]\n",
      "horse4-530.png is a horse\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[0.3361865]\n",
      "horse5-488.png is a horse\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.36934897]\n",
      "horse3-026.png is a horse\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0.4074695]\n",
      "horse2-314.png is a horse\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0.31193328]\n",
      "horse1-000.png is a horse\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0.2783963]\n",
      "horse1-298.png is a horse\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.5626258]\n",
      "horse4-503.png is a human\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[0.45430613]\n",
      "horse6-218.png is a horse\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.6200305]\n",
      "horse5-275.png is a human\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.5433709]\n",
      "horse6-161.png is a human\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.49732554]\n",
      "horse4-495.png is a horse\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[0.46673772]\n",
      "horse6-275.png is a horse\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[0.4087485]\n",
      "horse5-192.png is a horse\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[0.18372254]\n",
      "horse1-411.png is a horse\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[0.48605177]\n",
      "horse4-188.png is a horse\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[0.48696318]\n",
      "horse4-302.png is a horse\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[0.79351676]\n",
      "horse5-514.png is a human\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "[0.6662993]\n",
      "horse2-112.png is a human\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.37579104]\n",
      "horse2-441.png is a horse\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[0.3153961]\n",
      "horse3-055.png is a horse\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[0.38391227]\n",
      "horse5-478.png is a horse\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[0.3331709]\n",
      "horse3-099.png is a horse\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[0.46761963]\n",
      "horse4-072.png is a horse\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[0.18064515]\n",
      "horse1-384.png is a horse\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "[0.65762085]\n",
      "horse2-201.png is a human\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[0.4706448]\n",
      "horse2-294.png is a horse\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "[0.5659475]\n",
      "horse2-183.png is a human\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[0.722579]\n",
      "horse3-469.png is a human\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[0.40884528]\n",
      "horse2-544.png is a horse\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[0.54918027]\n",
      "horse6-089.png is a human\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[0.4598246]\n",
      "horse4-588.png is a horse\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[0.811525]\n",
      "horse5-519.png is a human\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "[0.44061005]\n",
      "horse1-204.png is a horse\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[0.7916343]\n",
      "horse5-123.png is a human\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[0.26329532]\n",
      "horse3-141.png is a horse\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[0.47098735]\n",
      "horse3-255.png is a horse\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[0.5761245]\n",
      "horse3-326.png is a human\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[0.6760543]\n",
      "horse5-083.png is a human\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[0.5432864]\n",
      "horse4-232.png is a human\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[0.7071594]\n",
      "horse5-565.png is a human\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[0.41037893]\n",
      "horse5-100.png is a horse\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[0.5313096]\n",
      "horse5-400.png is a human\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[0.39087647]\n",
      "horse2-254.png is a horse\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[0.7208527]\n",
      "horse3-521.png is a human\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "[0.2687575]\n",
      "horse3-070.png is a horse\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[0.4753377]\n",
      "horse1-127.png is a horse\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[0.58229357]\n",
      "horse4-548.png is a human\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[0.25639385]\n",
      "horse3-171.png is a horse\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[0.3917038]\n",
      "horse2-368.png is a horse\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[0.2109693]\n",
      "horse1-276.png is a horse\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# from google.colab import files\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import os\n",
    "import glob\n",
    "\n",
    "validation_horse_dir = os.path.join(\"./validation-horse-or-human/horses\")\n",
    "validation_horse_hames = os.listdir(validation_horse_dir)\n",
    "\n",
    "for fn in validation_horse_hames:\n",
    "\n",
    "    # predicting images\n",
    "    path = os.path.join(validation_horse_dir, fn)\n",
    "    img = load_img(path, target_size=(300, 300))\n",
    "    x = img_to_array(img)\n",
    "    x /= 255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "\n",
    "    if classes[0] > 0.5:\n",
    "        print(fn + \" is a human\")\n",
    "    else:\n",
    "        print(fn + \" is a horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET HORSES: ['horse32-2.png', 'horse33-0.png', 'horse28-1.png', 'horse23-0.png', 'horse11-8.png', 'horse34-9.png', 'horse43-6.png', 'horse15-1.png', 'horse09-4.png', 'horse29-3.png']\n",
      "TRAIN SET HUMANS: ['human04-29.png', 'human07-09.png', 'human16-03.png', 'human16-14.png', 'human04-20.png', 'human04-05.png', 'human09-28.png', 'human01-08.png', 'human13-16.png', 'human13-19.png']\n",
      "VAL SET HORSES: ['horse5-060.png', 'horse1-510.png', 'horse6-198.png', 'horse5-259.png', 'horse3-584.png', 'horse4-389.png', 'horse1-122.png', 'horse4-000.png', 'horse2-136.png', 'horse5-018.png']\n",
      "VAL SET HUMANS: ['valhuman05-15.png', 'valhuman02-10.png', 'valhuman05-12.png', 'valhuman01-24.png', 'valhuman01-13.png', 'valhuman01-22.png', 'valhuman01-17.png', 'valhuman05-26.png', 'valhuman02-21.png', 'valhuman01-20.png']\n",
      "total training horse images: 500\n",
      "total training human images: 527\n",
      "total validation horse images: 128\n",
      "total validation human images: 128\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory with training horse pictures\n",
    "train_horse_dir = os.path.join(\"./horse-or-human/horses\")\n",
    "\n",
    "# Directory with training human pictures\n",
    "train_human_dir = os.path.join(\"./horse-or-human/humans\")\n",
    "\n",
    "# Directory with validation horse pictures\n",
    "validation_horse_dir = os.path.join(\"./validation-horse-or-human/horses\")\n",
    "\n",
    "# Directory with validation human pictures\n",
    "validation_human_dir = os.path.join(\"./validation-horse-or-human/humans\")\n",
    "\n",
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(f\"TRAIN SET HORSES: {train_horse_names[:10]}\")\n",
    "\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(f\"TRAIN SET HUMANS: {train_human_names[:10]}\")\n",
    "\n",
    "validation_horse_hames = os.listdir(validation_horse_dir)\n",
    "print(f\"VAL SET HORSES: {validation_horse_hames[:10]}\")\n",
    "\n",
    "validation_human_names = os.listdir(validation_human_dir)\n",
    "print(f\"VAL SET HUMANS: {validation_human_names[:10]}\")\n",
    "\n",
    "\n",
    "print(f'total training horse images: {len(os.listdir(train_horse_dir))}')\n",
    "print(f'total training human images: {len(os.listdir(train_human_dir))}')\n",
    "print(\n",
    "    f'total validation horse images: {len(os.listdir(validation_horse_dir))}')\n",
    "print(\n",
    "    f'total validation human images: {len(os.listdir(validation_human_dir))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-11 23:21:46--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400e:811::201b, 2a00:1450:400e:80c::201b, 2a00:1450:400e:803::201b, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400e:811::201b|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "/tmp/inception_v3_w 100%[===================>]  83.84M  5.39MB/s    in 15s     \n",
      "\n",
      "2024-03-11 23:22:01 (5.65 MB/s) - /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 saved [87910968/87910968]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the weights file you downloaded into a variable\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# Initialize the base model.\n",
    "# Set the input shape and remove the dense layers.\n",
    "pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n",
    "                                include_top=False,\n",
    "                                weights=None)\n",
    "\n",
    "# Load the pre-trained weights you downloaded.\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Freeze the weights of the layers.\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d_35[0][0]']              \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_36[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_37[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_35 (MaxPooling2D  (None, 35, 35, 64)  0           ['activation_2[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 35, 35, 80)   5120        ['max_pooling2d_35[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_38[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_39[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_36 (MaxPooling2D  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 16, 16, 64)   12288       ['max_pooling2d_36[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_43[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 16, 16, 48)   9216        ['max_pooling2d_36[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_41[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_44[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_36[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 16, 16, 64)   12288       ['max_pooling2d_36[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_40[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_42[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_37 (MaxPooling2D  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_37[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_94[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_99[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_100[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_96[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_101[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_102[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_98[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_103[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_104[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 7, 7, 192)   576         ['conv2d_107[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 7, 7, 192)   576         ['conv2d_108[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 7, 7, 192)   576         ['conv2d_105[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 7, 7, 192)   576         ['conv2d_109[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 3, 3, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 3, 3, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 3, 3, 320)   960         ['conv2d_106[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 3, 3, 192)   576         ['conv2d_110[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_38 (MaxPooling2D  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_38[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_115[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, 3, 3, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_112[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_116[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_113[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_114[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_117[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_118[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, 3, 3, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 3, 3, 320)   960         ['conv2d_111[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 3, 3, 192)   576         ['conv2d_119[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3, 3, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_124[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, 3, 3, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_121[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_125[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_122[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_123[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_126[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_127[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 3, 3, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 3, 3, 320)   960         ['conv2d_120[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 3, 3, 192)   576         ['conv2d_128[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 3, 3, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "# Choose `mixed7` as the last layer of your base model\n",
    "last_layer = pre_trained_model.get_layer(\"mixed7\")\n",
    "print(\"last layer output shape: \", last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d_35[0][0]']              \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_36[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_37[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_35 (MaxPooling2D  (None, 35, 35, 64)  0           ['activation_2[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 35, 35, 80)   5120        ['max_pooling2d_35[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_38[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_39[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_36 (MaxPooling2D  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 16, 16, 64)   12288       ['max_pooling2d_36[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_43[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 16, 16, 48)   9216        ['max_pooling2d_36[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_41[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_44[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_36[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 16, 16, 64)   12288       ['max_pooling2d_36[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_40[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_42[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_37 (MaxPooling2D  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_37[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_94[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_99[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_100[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_96[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_101[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_102[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_98[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_103[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_104[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 37632)        0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 1024)         38536192    ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024)         0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1)            1025        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Append the dense network to the base model\n",
    "model = Model(pre_trained_model.input, x)\n",
    "\n",
    "# Print the model summary. See your dense network connected at the end.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training parameters\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 23:40:39.875623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-11 23:41:34.388491: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 - 58s - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0805 - val_accuracy: 0.9727 - 58s/epoch - 580ms/step\n",
      "Epoch 2/20\n",
      "100/100 - 47s - loss: 0.0227 - accuracy: 0.9900 - 47s/epoch - 467ms/step\n",
      "Epoch 3/20\n",
      "100/100 - 46s - loss: 0.0075 - accuracy: 0.9990 - 46s/epoch - 464ms/step\n",
      "Epoch 4/20\n",
      "100/100 - 46s - loss: 0.0104 - accuracy: 0.9950 - 46s/epoch - 462ms/step\n",
      "Epoch 5/20\n",
      "100/100 - 58s - loss: 0.0045 - accuracy: 0.9980 - 58s/epoch - 585ms/step\n",
      "Epoch 6/20\n",
      "100/100 - 59s - loss: 0.0119 - accuracy: 0.9970 - 59s/epoch - 595ms/step\n",
      "Epoch 7/20\n",
      "100/100 - 58s - loss: 0.0090 - accuracy: 0.9980 - 58s/epoch - 577ms/step\n",
      "Epoch 8/20\n",
      "100/100 - 51s - loss: 0.0040 - accuracy: 0.9980 - 51s/epoch - 506ms/step\n",
      "Epoch 9/20\n",
      "100/100 - 52s - loss: 0.0113 - accuracy: 0.9960 - 52s/epoch - 520ms/step\n",
      "Epoch 10/20\n",
      "100/100 - 62s - loss: 0.0080 - accuracy: 0.9980 - 62s/epoch - 618ms/step\n",
      "Epoch 11/20\n",
      "100/100 - 57s - loss: 0.0122 - accuracy: 0.9950 - 57s/epoch - 568ms/step\n",
      "Epoch 12/20\n",
      "100/100 - 56s - loss: 0.0223 - accuracy: 0.9960 - 56s/epoch - 557ms/step\n",
      "Epoch 13/20\n",
      "100/100 - 55s - loss: 0.0093 - accuracy: 0.9960 - 55s/epoch - 551ms/step\n",
      "Epoch 14/20\n",
      "100/100 - 55s - loss: 0.0049 - accuracy: 0.9980 - 55s/epoch - 550ms/step\n",
      "Epoch 15/20\n",
      "100/100 - 55s - loss: 0.0051 - accuracy: 0.9980 - 55s/epoch - 551ms/step\n",
      "Epoch 16/20\n",
      "100/100 - 55s - loss: 0.0088 - accuracy: 0.9970 - 55s/epoch - 553ms/step\n",
      "Epoch 17/20\n",
      "100/100 - 55s - loss: 0.0032 - accuracy: 0.9990 - 55s/epoch - 549ms/step\n",
      "Epoch 18/20\n",
      "100/100 - 55s - loss: 0.0074 - accuracy: 0.9960 - 55s/epoch - 547ms/step\n",
      "Epoch 19/20\n",
      "100/100 - 55s - loss: 0.0056 - accuracy: 0.9970 - 55s/epoch - 550ms/step\n",
      "Epoch 20/20\n",
      "100/100 - 55s - loss: 0.0124 - accuracy: 0.9970 - 55s/epoch - 554ms/step\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"./horse-or-human/\", batch_size=10, class_mode=\"binary\", target_size=(150, 150)\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    \"./validation-horse-or-human/\",\n",
    "    batch_size=10,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=(150, 150),\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=20,\n",
    "    validation_steps=50,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
